{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project_LSTM_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_VZkGbgO4yA"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpbnKsQeptXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4be2ed8-90c1-4c0e-ada6-0dc99a96a08e"
      },
      "source": [
        "!pip install sacremoses\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import sacremoses\n",
        "from torch.utils.data import dataloader, Dataset\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (0.0.49)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.63.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dlUYNvgPUXs"
      },
      "source": [
        "# Create DataLoaders\n",
        "Create Pytorch DataLoaders for our train, val, and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uJDfnVMxBsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "78600a6c-9ab5-414e-91ae-c90cfca96cd4"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
        "    This class inherits torch.utils.data.Dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, data_list, target_list, max_sent_length=128):\n",
        "        \"\"\"\n",
        "        @param data_list: list of data tokens \n",
        "        @param target_list: list of data targets \n",
        "        \"\"\"\n",
        "        self.data_list = data_list\n",
        "        self.target_list = target_list\n",
        "        self.max_sent_length = max_sent_length\n",
        "        assert (len(self.data_list) == len(self.target_list))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "        \n",
        "    def __getitem__(self, key, max_sent_length=None):\n",
        "        \"\"\"\n",
        "        Triggered when calling dataset[i]\n",
        "        \"\"\"\n",
        "        if max_sent_length is None:\n",
        "            max_sent_length = self.max_sent_length\n",
        "        token_idx = self.data_list[key][:max_sent_length]\n",
        "        label = self.target_list[key]\n",
        "        return [token_idx, label]\n",
        "\n",
        "    def spam_collate_func(self, batch):\n",
        "        \"\"\"\n",
        "        Customized function for DataLoader that dynamically pads the batch so that all \n",
        "        data have the same length\n",
        "        \"\"\" \n",
        "        data_list = [] # store padded sequences\n",
        "        label_list = [element[1] for element in batch]\n",
        "        max_batch_seq_len = None # the length of longest sequence in batch\n",
        "                                 # if it is less than self.max_sent_length\n",
        "                                 # else max_batch_seq_len = self.max_sent_length\n",
        "\n",
        "        # If self.max_sent_length is less than the length of longest sequence \n",
        "        # in the batch, use self.max_sent_length. Otherwise, use the length \n",
        "        # of longest sequence in the batch.\n",
        "        max_num_elements = max([len(element[0]) for element in batch])\n",
        "        if max_num_elements < self.max_sent_length:\n",
        "          max_batch_seq_len = max_num_elements\n",
        "        else:\n",
        "          max_batch_seq_len = self.max_sent_length\n",
        "\n",
        "        \"\"\"\n",
        "          # Pad the sequences in your data \n",
        "          # Trim the sequences that are longer than self.max_sent_length\n",
        "          # return padded data_list and label_list\n",
        "        \"\"\"\n",
        "\n",
        "        for element in batch:\n",
        "          sequence = element[0]\n",
        "          length = len(sequence)\n",
        "          print(max_num_elements)\n",
        "          print(max_batch_seq_len)\n",
        "          if length < max_batch_seq_len:\n",
        "            padding = [0 for _ in range(max_batch_seq_len - length)]\n",
        "            data_list.append(sequence + padding)\n",
        "          else:\n",
        "            data_list.append(sequence[:max_batch_seq_len])\n",
        "        \n",
        "        data_list = torch.tensor(data_list)\n",
        "        label_list = torch.tensor(label_list)\n",
        "\n",
        "        return [data_list, label_list]\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "max_sent_length=128\n",
        "train_dataset = SpamDataset(train_data_indices, train_labels, max_sent_length)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=train_dataset.spam_collate_func,\n",
        "                                           shuffle=True)\n",
        "\n",
        "val_dataset = SpamDataset(val_data_indices, val_labels, train_dataset.max_sent_length)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=train_dataset.spam_collate_func,\n",
        "                                           shuffle=False)\n",
        "\n",
        "test_dataset = SpamDataset(test_data_indices, test_labels, train_dataset.max_sent_length)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=train_dataset.spam_collate_func,\n",
        "                                           shuffle=False)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-af6e6ceac5c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mmax_sent_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpamDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sent_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n\u001b[1;32m     79\u001b[0m                                            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data_indices' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWgRGaCWf4Zz"
      },
      "source": [
        "Let's try to print out an batch from train_loader.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O8R_KhwxULI"
      },
      "source": [
        "data_batch, labels = next(iter(train_loader))\n",
        "print(\"data batch dimension: \", data_batch.size())\n",
        "print(\"data_batch: \", data_batch)\n",
        "print(\"labels: \", labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data_batch[0]))"
      ],
      "metadata": {
        "id": "uJIdLiyUSP4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpdnYbPIgNXw"
      },
      "source": [
        "# Build BiLSTM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOYEmADNDVIh"
      },
      "source": [
        "# First import torch related libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTMClassifier classification model\n",
        "    \"\"\"\n",
        "    def __init__(self, embeddings, hidden_size, num_layers, num_classes, bidirectional, dropout_prob=0.3):\n",
        "        \"\"\"\n",
        "           Components of BiLSTM Classifier model\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embedding_layer = self.load_pretrained_embeddings(embeddings)\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embeddings.shape[1], hidden_size=hidden_size, \n",
        "            num_layers=num_layers, dropout=dropout_prob, \n",
        "            batch_first=True, bidirectional=bidirectional)\n",
        "        self.non_linearity = nn.ReLU() # For example, ReLU\n",
        "        self.clf = nn.Linear(hidden_size*2, 2) # classifier layer\n",
        "        \n",
        "    \n",
        "    def load_pretrained_embeddings(self, embeddings):\n",
        "        embedding_layer = nn.Embedding(embeddings.shape[0], embeddings.shape[1], padding_idx=0)\n",
        "        embedding_layer.weight.data = torch.Tensor(embeddings).float()\n",
        "        return embedding_layer\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        logits = None\n",
        "        v_embedded = self.embedding_layer(inputs)\n",
        "        v_dropout = self.dropout(v_embedded)\n",
        "        v_bilstm, _ = self.lstm(v_dropout)\n",
        "        v_avg_pool = torch.mean(v_bilstm, 1)\n",
        "        v_nonlinear = self.non_linearity(v_avg_pool)\n",
        "        v_classify = self.clf(v_nonlinear)\n",
        "\n",
        "        return v_classify"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpCXZCO7iuEL"
      },
      "source": [
        "# Initialize the BiLSTM classifier model, criterion and optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaPW_CjlK0F7"
      },
      "source": [
        "# BiLSTM hyperparameters\n",
        "hidden_size = 32\n",
        "num_layers = 1\n",
        "num_classes = 2\n",
        "bidirectional=True\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# if cuda exists, use cuda, else run on cpu\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "model = LSTMClassifier(embeddings, hidden_size, num_layers, num_classes, bidirectional)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwkHYzbQikT4"
      },
      "source": [
        "# Train model with early stopping (10 pts)\n",
        "\n",
        "Train the model for `NUM_EPOCHS`. \n",
        "Keep track of training loss.  \n",
        "Compute the validation accuracy after each epoch. Keep track of the best validation accuracy and save the model with the best validation accuracy.  \n",
        "\n",
        "If the validation accuracy does not improve for more than `early_stop_patience` number of epochs in a row, stop training. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "    accuracy = None\n",
        "    n_correct = n_total = 0 \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (data_batch, batch_labels) in dataloader:\n",
        "            out = model(data_batch.to(device))\n",
        "            max_scores, preds = out.max(dim=1)\n",
        "            n_correct += np.sum(preds.cpu().numpy() == batch_labels.numpy())\n",
        "            n_total += out.shape[0]\n",
        "    accuracy = n_correct*1.0/n_total\n",
        "    return accuracy "
      ],
      "metadata": {
        "id": "s5_H1tmQ-sVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOlop_TMOD9V"
      },
      "source": [
        "train_loss_history = []\n",
        "val_accuracy_history = []\n",
        "best_val_accuracy = 0\n",
        "n_no_improve = 0\n",
        "early_stop_patience=2\n",
        "NUM_EPOCHS=10\n",
        "  \n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "    model.train()  # this enables dropout/regularization\n",
        "    for i, (data_batch, batch_labels) in enumerate(train_loader):\n",
        "        \"\"\"\n",
        "           Code for training lstm\n",
        "        \"\"\"\n",
        "        preds = model(data_batch.to(device))\n",
        "        loss = criterion(preds, batch_labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss_history.append(loss.item())\n",
        "        \n",
        "\n",
        "    \"\"\"\n",
        "        Code for tracking best validation accuracy, saving the best model, and early stopping\n",
        "        # Compute validation accuracy after each training epoch using `evaluate` function\n",
        "        # Keep track of validation accuracy in `val_accuracy_history`\n",
        "        # save model with best validation accuracy, hint: torch.save(model, 'best_model.pt')\n",
        "        # Early stopping: \n",
        "        # stop training if the validation accuracy does not improve for more than `early_stop_patience` runs\n",
        "    \"\"\"\n",
        "    accuracy = evaluate(model, val_loader, device)\n",
        "    val_accuracy_history.append(accuracy)\n",
        "    torch.save(model, 'best_model.pt')\n",
        "    if best_val_accuracy < accuracy:\n",
        "      best_val_accuracy = accuracy\n",
        "    else:\n",
        "      n_no_improve += 1\n",
        "    if n_no_improve == early_stop_patience:\n",
        "      break\n",
        "\n",
        "print(\"Best validation accuracy is: \", best_val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hhFpkMHnT7Z"
      },
      "source": [
        "To avoid overfiting of our model, we use early stopping. Particularly when training a large model, early stopping can help us stop training when at the point where the model stops making genaralizations about the data and begins learning statistical noise that would cause the model to overfit.This would make our model less useful and have less performance when tested on new data/datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I58rTeMEg05M"
      },
      "source": [
        "# Draw training curve \n",
        "X-axis: training steps, Y-axis: training loss\n",
        "\n",
        "Make sure to draw your own curves. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyalZo6tSXo_"
      },
      "source": [
        "pd.Series(train_loss_history).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMiI_u4ggvQK"
      },
      "source": [
        "# Validation accuracy curve\n",
        "X-axis: Epochs, Y-axis: validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt8iNjFwPVtc"
      },
      "source": [
        "pd.Series(val_accuracy_history).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqanG00Ggluj"
      },
      "source": [
        "## You should expect to get test accuracy > 0.95."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw6KtE2uSf1X"
      },
      "source": [
        "# Reload best model from saved checkpoint\n",
        "# Compute test accuracy\n",
        "#device = \"cuda:0\"\n",
        "model = torch.load('best_model.pt')\n",
        "test_accuracy = evaluate(model, test_loader, device)\n",
        "print(test_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
